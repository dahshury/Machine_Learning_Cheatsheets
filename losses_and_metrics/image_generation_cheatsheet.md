### Image Generation Loss Functions

| Loss Function       | Purpose | Formula | Key Points |
|---------------------|---------|---------|------------|
| **Mean Squared Error (MSE)** | Measures the average squared difference between generated and target images | ${\mathcal{L}_{\text{MSE}} = \frac{1}{N} \sum_{i=1}^{N} \| y_i - \hat{y}_i \|^2}$ <br><br> *where:* <br> $y_i$: True pixel value <br> $\hat{y}_i$: Generated pixel value | - **Pros:** Simple and easy to compute <br> - **Cons:** Sensitive to outliers, may not capture perceptual differences |
| **L1 Loss (Mean Absolute Error)** | Measures the average absolute difference between generated and target images | ${\mathcal{L}_{\text{MAE}} = \frac{1}{N} \sum_{i=1}^{N}  \|y_i - \hat{y}_i\|}$ <br><br> *where:* <br> $y_i$: True pixel value <br> $\hat{y}_i$: Generated pixel value | - **Pros:** Less sensitive to outliers than MSE <br> - **Cons:** May still not capture perceptual differences |
| **Adversarial Loss (GAN Loss)** | Encourages the generator to produce realistic images | ${\mathcal{L}_{\text{adv}} = \log(D(x)) + \log(1 - D(G(z)))}$ <br><br> *where:* <br> $D(x)$: Discriminator's output for real image $x$ <br> $G(z)$: Generator's output for noise $z$ | - **Pros:** Produces highly realistic images <br> - **Cons:** Training can be unstable, sensitive to hyperparameters |
| **Perceptual Loss** | Encourages the generator to produce images perceptually similar to target | ${\mathcal{L}_{\text{perc}} = \sum_{l=1}^{L} \| \phi_l(y) - \phi_l(\hat{y}) \|^2}$ <br><br> *where:* <br> $\phi_l$: Feature map from layer $l$ of a pre-trained network | - **Pros:** Captures perceptual differences better than pixel-wise losses <br> - **Cons:** Computationally expensive, depends on choice of pre-trained network |
| **Style Loss** | Encourages the generator to produce images with similar style to target | ${\mathcal{L}_{\text{style}} = \sum_{l=1}^{L} \| \text{Gram}(\phi_l(y)) - \text{Gram}(\phi_l(\hat{y})) \|^2}$ <br><br> *where:* <br> $\text{Gram}(\phi_l)$: Gram matrix of feature map $\phi_l$ | - **Pros:** Effective for style transfer tasks <br> - **Cons:** May not be sufficient for content fidelity alone |
| **Content Loss** | Ensures the generated image has similar content to the target image | ${\mathcal{L}_{\text{content}} = \| \phi_L(y) - \phi_L(\hat{y}) \|^2}$ <br><br> *where:* <br> $\phi_L$: Feature map from a deep layer of a pre-trained network | - **Pros:** Retains important image details <br> - **Cons:** Needs to be combined with other losses for full image quality |
| **VGG Loss**        | Uses features from a VGG network to compare generated and target images | ${\mathcal{L}_{\text{VGG}} = \sum_{i=1}^{N} \| \phi_i(y) - \phi_i(\hat{y}) \|^2}$ <br><br> *where:* <br> $\phi_i$: Feature map from the $i$-th layer of a VGG network | - **Pros:** Provides a good balance between texture and content fidelity <br> - **Cons:** Computationally expensive, relies on pre-trained VGG network |
| **Total Variation Loss** | Encourages spatial smoothness in the generated image | ${\mathcal{L}_{\text{TV}} = \sum_{i,j} \left \| \hat{y}_{i+1,j} - \hat{y}_{i,j} \right \| + \left  \| \hat{y}_{i,j+1} - \hat{y}_{i,j} \right \|}$ <br><br> *where:* <br> $\hat{y}_{i,j}$: Generated pixel value at position $(i,j)$ | - **Pros:** Reduces noise and artifacts <br> - **Cons:** May oversmooth fine details in the image |

---

### Image Generation Evaluation Metrics

| Metric             | Purpose | Formula | Key Points |
|--------------------|---------|---------|------------|
| **Inception Score (IS)** | Measures the quality and diversity of generated images | ${\text{IS} = \exp\left(\mathbb{E}_x[D_{\text{KL}}(p(y\|x) \| p(y))]\right)}$ <br><br> *where:* <br> $p(y\|x)$: Conditional label distribution <br> $p(y)$: Marginal label distribution | - **Pros:** Easy to compute, widely used <br> - **Cons:** Sensitive to mode collapse, relies on pre-trained model |
| **Frechet Inception Distance (FID)** | Measures the similarity between generated and real images | ${\text{FID} = \| \mu_g - \mu_r \|^2 + \text{Tr}(\Sigma_g + \Sigma_r - 2(\Sigma_g \Sigma_r)^{1/2})}$ <br><br> *where:* <br> $\mu_g, \Sigma_g$: Mean and covariance of generated features <br> $\mu_r, \Sigma_r$: Mean and covariance of real features | - **Pros:** More robust than IS, accounts for both quality and diversity <br> - **Cons:** Computationally expensive, sensitive to choice of features |
| **Peak Signal-to-Noise Ratio (PSNR)** | Measures the quality of the generated image by comparing it to the target image | ${\text{PSNR} = 10 \cdot \log_{10}\left(\frac{L^2}{\text{MSE}}\right)}$ <br><br> *where:* <br> $L$: Maximum possible pixel value <br> $\text{MSE}$: Mean squared error between generated and target images | - **Pros:** Simple to compute, interpretable <br> - **Cons:** Not perceptually meaningful, sensitive to slight changes |
| **Structural Similarity Index (SSIM)** | Measures the perceptual similarity between generated and target images | ${\text{SSIM}(x, \hat{x}) = \frac{(2\mu_x\mu_{\hat{x}} + C_1)(2\sigma_{x\hat{x}} + C_2)}{(\mu_x^2 + \mu_{\hat{x}}^2 + C_1)(\sigma_x^2 + \sigma_{\hat{x}}^2 + C_2)}}$ <br><br> *where:* <br> $\mu_x, \mu_{\hat{x}}$: Mean of original and generated images <br> $\sigma_x^2, \sigma_{\hat{x}}^2$: Variance of original and generated images <br> $\sigma_{x\hat{x}}$: Covariance of original and generated images <br> $C_1, C_2$: Stability constants | - **Pros:** Correlates well with human perception <br> - **Cons:** Can be sensitive to structural artifacts |
| **Multi-Scale Structural Similarity (MS-SSIM)** | Extends SSIM by considering image details at multiple scales | ${\text{MS-SSIM} = \prod_{j=1}^{M} \text{SSIM}_j(x, \hat{x})^{\alpha_j}}$ <br><br> *where:* <br> $\text{SSIM}_j$: SSIM at scale $j$ <br> $\alpha_j$: Weight for scale $j$ | - **Pros:** More robust to scale changes, better correlates with perception <br> - **Cons:** More computationally expensive than SSIM |
