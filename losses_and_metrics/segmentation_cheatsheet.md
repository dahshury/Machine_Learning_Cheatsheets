### Segmentation Loss Functions

| Loss Function           | Purpose | Formula | Key Points |
|-------------------------|---------|---------|------------|
| **Binary Cross-Entropy Loss** | Measures performance for binary segmentation tasks | **$\text{BCE Loss} = -\frac{1}{N} \sum_{i=1}^N [y_i \log(p_i) + (1 - y_i) \log(1 - p_i)]$** <br><br> *where:* <br> $y_i$: True binary label (0 or 1) <br> $p_i$: Predicted probability <br> $N$: Number of pixels | - Suitable for binary segmentation<br>- Sensitive to class imbalance |
| **Categorical Cross-Entropy Loss** | Measures performance for multi-class segmentation tasks | **$\text{CCE Loss} = -\frac{1}{N} \sum_{i=1}^N \sum_{j=1}^M y_{ij} \log(p_{ij})$** <br><br> *where:* <br> $y_{ij}$: True probability for class $j$ at pixel $i$ <br> $p_{ij}$: Predicted probability for class $j$ at pixel $i$ <br> $N$: Number of pixels <br> $M$: Number of classes | - Suitable for multi-class segmentation<br>- Assumes mutually exclusive classes |
| **Dice Loss**           | Measures overlap between predicted and true segmentation | **$\text{Dice Loss} = 1 - \frac{2 \cdot \sum_{i=1}^N (y_i \cdot p_i)}{\sum_{i=1}^N y_i + \sum_{i=1}^N p_i}$** <br><br> *where:* <br> $y_i$: True binary label <br> $p_i$: Predicted probability <br> $N$: Number of pixels | - Directly correlates with the Dice coefficient<br>- Useful for imbalanced data |
| **Jaccard Loss**        | Measures similarity between predicted and true segmentation | **$\text{Jaccard Loss} = 1 - \frac{\sum_{i=1}^N (y_i \cdot p_i)}{\sum_{i=1}^N (y_i + p_i - y_i \cdot p_i)}$** <br><br> *where:* <br> $y_i$: True binary label <br> $p_i$: Predicted probability <br> $N$: Number of pixels | - Measures intersection over union (IoU)<br>- Useful for imbalanced data |
| **Tversky Loss**        | Generalizes Dice Loss with a parameter $\alpha$ and $\beta$ for false positives and false negatives | **$\text{Tversky Loss} = 1 - \frac{\sum_{i=1}^N (y_i \cdot p_i)}{\sum_{i=1}^N (y_i \cdot p_i) + \alpha \cdot \sum_{i=1}^N (1 - y_i) \cdot p_i + \beta \cdot \sum_{i=1}^N y_i \cdot (1 - p_i)}$** <br><br> *where:* <br> $y_i$: True binary label <br> $p_i$: Predicted probability <br> $\alpha$: Weight for false positives <br> $\beta$: Weight for false negatives <br> $N$: Number of pixels | - Flexible weighting for false positives and false negatives<br>- Adaptable for different data distributions |
| **Focal Loss**          | Focuses on hard-to-classify pixels by down-weighting easy examples | **$\text{Focal Loss} = -\frac{1}{N} \sum_{i=1}^N \alpha (1 - p_i)^\gamma \log(p_i)$** <br><br> *where:* <br> $p_i$: Predicted probability <br> $\alpha$: Balancing factor <br> $\gamma$: Focusing parameter <br> $N$: Number of pixels | - Focuses on hard examples<br>- Reduces the impact of easy examples |

### Segmentation Metrics

| Metric                   | Purpose | Formula | Key Points |
|--------------------------|---------|---------|------------|
| **Accuracy**             | Measures overall correctness of segmentation | **$\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}$** <br><br> *where:* <br> $\text{TP}$: True Positives <br> $\text{TN}$: True Negatives <br> $\text{FP}$: False Positives <br> $\text{FN}$: False Negatives | - Simple and intuitive<br>- Can be misleading for imbalanced datasets |
| **Precision**            | Measures the accuracy of positive predictions | **$\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}$** <br><br> *where:* <br> $\text{TP}$: True Positives <br> $\text{FP}$: False Positives | - Important when the cost of false positives is high |
| **Recall (Sensitivity)** | Measures the ability to find all positive instances | **$\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$** <br><br> *where:* <br> $\text{TP}$: True Positives <br> $\text{FN}$: False Negatives | - Important when the cost of false negatives is high |
| **F1 Score**             | Harmonic mean of precision and recall | **$\text{F1 Score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$** <br><br> *where:* <br> $\text{Precision}$: Precision <br> $\text{Recall}$: Recall | - Balances precision and recall<br>- Useful for imbalanced datasets |
| **IoU (Intersection over Union)** | Measures the overlap between predicted and true segmentation | **$\text{IoU} = \frac{\text{TP}}{\text{TP} + \text{FP} + \text{FN}}$** <br><br> *where:* <br> $\text{TP}$: True Positives <br> $\text{FP}$: False Positives <br> $\text{FN}$: False Negatives | - Measures overlap between predicted and true areas<br>- Useful for evaluating segmentation quality |
| **Dice Coefficient**     | Measures overlap between predicted and true segmentation | **$\text{Dice} = \frac{2 \cdot \text{TP}}{2 \cdot \text{TP} + \text{FP} + \text{FN}} = \frac{2 \sum p_i y_i}{\sum p_i + \sum y_i}$** <br><br> *where:* <br> $\text{TP}$: True Positives <br> $\text{FP}$: False Positives <br> $\text{FN}$: False Negatives | - Directly correlates with Dice Loss<br>- Useful for imbalanced data |
| **Jaccard Index**        | Measures similarity between predicted and true segmentation | **$\text{Jaccard Index} = \frac{\text{TP}}{\text{TP} + \text{FP} + \text{FN}}$** <br><br> *where:* <br> $\text{TP}$: True Positives <br> $\text{FP}$: False Positives <br> $\text{FN}$: False Negatives | - Measures intersection over union (IoU)<br>- Useful for imbalanced data |
