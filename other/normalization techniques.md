### Normalization Techniques

| **Technique**             | **Description**                                               | **Mathematical Formula**                               | **Variables**                     | **Advantages**                                         | **Disadvantages**                                       |
|---------------------------|---------------------------------------------------------------|-------------------------------------------------------|-----------------------------------|--------------------------------------------------------|--------------------------------------------------------|
| **Min-Max Normalization** | Scales features to a fixed range, usually $[0, 1]$ or $[-1, 1]$. | $ x' = \frac{x - \text{min}}{\text{max} - \text{min}} $                        | $ x' $ = normalized value, $ x $ = original value, $ \text{min} $ = minimum value, $ \text{max} $ = maximum value | Simple, preserves relationships between data points. | Sensitive to outliers, does not handle outliers well. |
| **Mean Normalization**    | Centers data around 0 by subtracting the mean and dividing by the range. | $ x' = \frac{x - \mu}{\text{max} - \text{min}} $                           | $ x' $ = normalized value, $ x $ = original value, $ \mu $ = mean, $ \text{max} $ = maximum value, $ \text{min} $ = minimum value | Centers data around 0, makes data zero-centered. | Sensitive to outliers, range may still be large. |
| **Log Transformation**    | Applies a logarithm to the data to reduce skewness.           | $ x' = \log(x + c) $                                     | $ x' $ = transformed value, $ x $ = original value, $ c $ = constant (e.g., 1 to avoid $\log(0)$) | Reduces skewness, useful for exponential data distributions. | May not handle zero or negative values well. |
| **Z-Score Normalization (Standardization)** | Scales data to have a mean of 0 and a standard deviation of 1. | $ x' = \frac{x - \mu}{\sigma} $                                     | $ x' $ = normalized value, $ x $ = original value, $ \mu $ = mean, $ \sigma $ = standard deviation | Handles outliers better, data follows a normal distribution. | Not bounded, can lead to negative values. |
| **Robust Scaling**        | Uses median and interquartile range (IQR) for normalization. | $ x' = \frac{x - \text{median}}{\text{IQR}} $                              | $ x' $ = normalized value, $ x $ = original value, $ \text{median} $ = median value, $ \text{IQR} $ = interquartile range | Robust to outliers, scales features with median and IQR. | May not work well if data is not roughly symmetric. |
| **L1 Normalization**      | Scales feature vector to unit L1 norm (sum of absolute values). | $ x' = \frac{x}{\| x \|_1} $                                | $ x' $ = normalized vector, $ \| x \|_1 $ = L1 norm of vector $ x $ | Useful for sparse data, preserves sparsity of feature vectors. | Can lead to numerical instability in some cases. |
| **L2 Normalization**      | Scales feature vector to unit norm (length 1).               | $ x' = \frac{x}{\| x \|_2} $                                | $ x' $ = normalized vector, $ \| x \|_2 $ = L2 norm of vector $ x $ | Ensures all features have the same scale, useful for text classification. | Can distort feature magnitude, especially for sparse data. |
| **MaxAbs Normalization**  | Scales each feature by its maximum absolute value.            | $ x' = \frac{x}{\max(\| x \|)} $                                 | $ x' $ = normalized value, $ x $ = original value, $ \max(\| x \|) $ = maximum absolute value | Preserves sparsity, bounded between $[-1, 1]$. | Sensitive to outliers, normalization might not be uniform. |
| **Box-Cox Transformation**| Applies a power transformation to stabilize variance and make data more normal. | $ x' = \frac{x^\lambda - 1}{\lambda}, \quad \lambda \neq 0 $ <br> $ x' = \log(x) $ for $ \lambda = 0 $ | $ x' $ = transformed value, $ x $ = original value, $ \lambda $ = transformation parameter | Flexible, can handle a variety of distributions. | Requires parameter tuning, may not be intuitive. |
| **Quantile Transformation** | Maps features to a uniform or normal distribution based on their quantiles. | $ x' = F(x) $, where $ F(x) $ is the quantile function     | $ x' $ = transformed value, $ F(x) $ = quantile function | Transforms data to uniform or normal distribution, robust to outliers. | Computationally intensive, may lose interpretability. |