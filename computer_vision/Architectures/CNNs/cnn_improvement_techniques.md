# Techniques used to improve CNN architectures

| **Technique**                     | **Description**                                                                                                                                                    | **Networks that Use It**                                                                                   |
|-----------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|
| **Feature Pyramid Network (FPN)** | Combines multi-scale feature maps from different layers of a backbone network to handle objects of different sizes in tasks like detection and segmentation.         | - Faster R-CNN with FPN<br>- Mask R-CNN<br>- RetinaNet                                                      |
| **Residual Connections**          | Shortcuts or skip connections that bypass one or more layers to prevent vanishing gradients and allow deeper networks to be trained.                                | - ResNet (Residual Networks)<br>- ResNeXt<br>- WideResNet                                                    |
| **Dilated (Atrous) Convolutions** | Expands the receptive field without increasing the number of parameters or the resolution, improving context capture in tasks like segmentation.                    | - DeepLab (v2, v3)<br>- WaveNet<br>- PSPNet                                                                  |
| **Attention Mechanisms**          | Focuses on the most relevant parts of the input for a task, improving model performance by weighting important features more heavily.                               | - Transformer<br>- SENet (Squeeze-and-Excitation Networks)<br>- Vision Transformer (ViT)<br>- EfficientNet   |
| **Skip Connections**              | Bypass some layers to add features from earlier layers to later ones, preventing loss of spatial information, especially in generative models and autoencoders.     | - U-Net (for medical image segmentation)<br>- Densenet<br>- Fully Convolutional Networks (FCNs)              |
| **Batch Normalization**           | Normalizes the input of each layer to improve convergence and stability of deep networks, reducing internal covariate shift.                                        | - ResNet<br>- Inception<br>- VGG (with added batch norm)<br>- EfficientNet                                    |
| **Dropout**                       | Randomly drops units (and their connections) during training to prevent overfitting and improve generalization.                                                     | - AlexNet<br>- VGGNet<br>- Inception v4<br>- GoogleNet                                                       |
| **Squeeze-and-Excitation (SE)**   | Enhances the network's sensitivity to channel-wise features by learning a dynamic weighting of channels in a way that improves performance on classification tasks.   | - SENet<br>- EfficientNet<br>- ResNeXt                                                                      |
| **Self-Attention**                | Allows long-range dependencies and global context to be captured in images, used in dense tasks like image generation or segmentation.                              | - Transformer<br>- Vision Transformer (ViT)<br>- Attention U-Net                                             |
| **Depthwise Separable Convolutions**| Factorizes a standard convolution into a depthwise and a pointwise convolution, reducing the model size and computation while retaining accuracy.                   | - MobileNet<br>- Xception<br>- EfficientNet                                                                  |
| **Spatial Pyramid Pooling (SPP)** | Uses multiple pooling layers to aggregate multi-scale contextual information by capturing features from different-sized receptive fields.                          | - SPP-Net<br>- YOLOv3<br>- DeepLab                                                                           |
| **Multi-Scale Feature Learning**  | Combines features from multiple resolutions, often to deal with object detection or segmentation across different scales.                                           | - FPN<br>- U-Net<br>- PSPNet<br>- Hourglass Network                                                          |
| **Gradient Clipping**             | Limits the magnitude of the gradients during backpropagation to avoid exploding gradients, which helps in stabilizing training of deep networks.                    | - LSTMs/GRUs (used in recurrent networks)<br>- GPT-3 (transformers)<br>- Neural ODEs                                                               |
| **Hierarchical Feature Learning** | Uses features learned at different hierarchical levels (like in deep layers) for better generalization and handling of complex visual tasks.                        | - DeepLab v3<br>- HRNet (High-Resolution Network)<br>- FPN<br>- NASNet                                       |
| **Inverted Residuals**            | Uses a lightweight convolution block where the number of channels is first expanded then compressed, reducing memory usage while retaining accuracy.               | - MobileNetV2<br>- EfficientNet<br>- MNASNet                                                                 |
| **Non-local Block**               | Captures long-range dependencies by computing relationships between distant elements in the feature maps, improving global context understanding.                   | - Non-local Networks<br>- ResNet variants with Non-local attention                                           |
| **Weight Standardization**        | Normalizes the weight distribution of each convolution layer, improving convergence speed and generalization.                                                       | - Fixup ResNet<br>- Classy Vision<br>- TResNet                                                               |
