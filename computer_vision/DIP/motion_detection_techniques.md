### Table: Motion Detection Techniques

| **Function & Arguments** | **Description** | **Formula & Details** | **Advantages** | **Disadvantages** |
|---------------------------|-----------------|------------------------|----------------|--------------------|
|  **Frame Differencing** `cv2.absdiff(frame1, frame2)` <br> Computes the absolute difference between two frames **frame1** and **frame2**. | Identifies moving regions by calculating pixel-wise intensity differences. | $D(x, y) = \|I_1(x, y) - I_2(x, y)\|$ <br> *where:* <br> $(I_1(x, y), I_2(x, y))$: Intensities of two frames. | - Simple and efficient.<br>- Works well for static cameras. | - Sensitive to noise and lighting changes.<br>- Requires careful frame selection. |
| `cv2.calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags)` <br> Estimates dense optical flow between consecutive frames **prev** and **next**. | Computes motion vectors for each pixel using the Gunnar Farneback algorithm. | Uses polynomial expansion: <br> $I(x, y, t) = I(x + u, y + v, t + 1)$ <br> *where:* <br> $(u, v)$: Flow vectors | - Produces dense motion fields.<br>- Useful for detailed motion analysis. | - Computationally expensive.<br>- Sensitive to fast motion and occlusions. |
| **Optical Flow** `cv2.calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts, status)` <br> Tracks sparse features from **prevImg** to **nextImg** using the Lucas-Kanade method. | Tracks motion by minimizing intensity differences over time. | Solves: $\min \|I(x, y) - I(x + u, y + v)\|$ <br> *where:* <br> $(u, v)$: Flow vectors | - Fast and efficient.<br>- Works well for small, sparse movements. | - Requires good initial keypoints.<br>- Cannot handle large displacements. |
| **Background Subtraction 1** `cv2.createBackgroundSubtractorMOG2()` <br> Creates a background subtractor using Gaussian Mixture Models (MOG2). | Separates foreground (motion) from background by modeling pixel intensity distributions. | Models pixel values as a mixture of Gaussians. | - Handles gradual lighting changes.<br>- Automatically adapts to dynamic backgrounds. | - Computationally intensive.<br>- Sensitive to fast or erratic motion. |
| **Background Subtraction 2** `cv2.createBackgroundSubtractorKNN()` <br> Creates a background subtractor using the K-Nearest Neighbors (KNN) method. | Segments motion by classifying pixel intensities based on the nearest neighbors. | Classifies foreground if pixel is distant from its $(k)$-nearest neighbors. | - Handles dynamic backgrounds.<br>- Robust to noise. | - Slower than simpler methods.<br>- Parameter tuning required. |
| `cv2.Canny(img, threshold1, threshold2)` <br> Detects edges in the image **img** by finding areas of intensity change. | Identifies motion indirectly by detecting moving edges. | Computes gradient magnitude and direction: <br> $G = \sqrt{G_x^2 + G_y^2}$ <br> *where:* <br> $(G_x, G_y)$: Gradients in x and y directions. | - Fast and simple.<br>- Can highlight moving boundaries. | - Not motion-specific.<br>- Sensitive to noise. |
| `cv2.threshold(diff, thresh, maxval, type)` <br> Binarizes the difference image **diff** using a fixed threshold **thresh**. | Highlights moving areas by thresholding intensity changes. | $T(x, y) = \begin{cases} \text{maxval} & \text{if } D(x, y) \geq \text{thresh} \\ 0 & \text{otherwise} \end{cases}$ | - Simple and fast.<br>- Good for static cameras. | - Requires manual threshold selection.<br>- Sensitive to noise. |
| `cv2.findContours(binaryImg, mode, method)` <br> Detects contours in a binary motion mask **binaryImg**. | Finds outlines of moving objects in a binarized motion map. | Outputs contours $C$: $(x_1, y_1), (x_2, y_2), \dots$ | - Useful for object tracking.<br>- Supports hierarchical analysis. | - Requires clean binary input.<br>- Sensitive to noise. |
| `cv2.calcHist([roi], channels, mask, histSize, ranges)` <br> Calculates a histogram for a region of interest **roi**. | Tracks motion regions using intensity histograms. | $H(i) = \sum_{x, y} \delta(I(x, y) - i)$ | - Efficient for object appearance tracking.<br>- Works well with color models. | - Requires stable lighting.<br>- Not robust to occlusions. |
